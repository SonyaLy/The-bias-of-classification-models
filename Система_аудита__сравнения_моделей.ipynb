{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe5933f",
   "metadata": {},
   "source": [
    "# Аудит и сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53e85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from warnings import catch_warnings, filterwarnings\n",
    "\n",
    "from aif360.sklearn.metrics import difference, ratio\n",
    "from aif360.sklearn.metrics import average_odds_difference, equal_opportunity_difference, statistical_parity_difference, disparate_impact_ratio, consistency_score, generalized_entropy_index, generalized_entropy_error, between_group_generalized_entropy_error, theil_index, coefficient_of_variation\n",
    "\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sk_metric\n",
    "from typing import List, Tuple, Type, Union\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "ArrayLike = Type[Union[List, Tuple, np.ndarray, pd.Series, pd.DataFrame]]\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1dcfd",
   "metadata": {},
   "source": [
    "#### Базовые метрики, отсутствующие в библиотеках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6837f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_prediction_results(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    tn, fp, fn, tp = sk_metric.confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    counts = {\"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn}\n",
    "    return counts\n",
    "\n",
    "def epsilon():\n",
    "    return np.finfo(np.float64).eps\n",
    "\n",
    "# Проверяет, находится ли результат в ожидаемом диапазоне для метрики и возвращает этот результат, если он действителен\n",
    "def check_result(res: Number, metric_name: str, custom_lower: Number = None, custom_upper: Number = None,):\n",
    "    if np.isnan(res):\n",
    "        return res\n",
    "    else:\n",
    "        lower = 0 - 100 * epsilon() if custom_lower is None else custom_lower\n",
    "        upper = 1 + 100 * epsilon() if custom_upper is None else custom_upper\n",
    "        if not lower < res < upper:\n",
    "            raise ValueError(f\"{metric_name} result out of range ({res})\")\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "# возвращает соотношение (исключая деление на ноль)\n",
    "def ratio(numerator: Number, denominator: Number):\n",
    "    if denominator == 0:\n",
    "        return numerator / epsilon()\n",
    "    else:\n",
    "        return numerator / denominator\n",
    "\n",
    "\n",
    "\"\"\" Метрики \"\"\"\n",
    "\n",
    "# accuracy\n",
    "def accuracy(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    rprt = binary_prediction_results(y_true, y_pred)\n",
    "    res = ratio(rprt[\"TP\"] + rprt[\"TN\"], y_true.shape[0])\n",
    "    return check_result(res, \"Accuracy\")\n",
    "\n",
    "# balanced accuracy\n",
    "def balanced_accuracy(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    sens = true_positive_rate(y_true, y_pred)\n",
    "    spec = true_negative_rate(y_true, y_pred)\n",
    "    res = ratio(sens + spec, 2)\n",
    "    return check_result(res, \"Balanced Accuracy\")\n",
    "\n",
    "# false negative rate\n",
    "def false_negative_rate(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    rprt = binary_prediction_results(y_true, y_pred)\n",
    "    res = ratio(rprt[\"FN\"], rprt[\"FN\"] + rprt[\"TP\"])\n",
    "    return check_result(res, \"FNR\")\n",
    "\n",
    "# false positive rate\n",
    "def false_positive_rate(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    rprt = binary_prediction_results(y_true, y_pred)\n",
    "    res = ratio(rprt[\"FP\"], rprt[\"FP\"] + rprt[\"TN\"])\n",
    "    return check_result(res, \"FPR}\")\n",
    "\n",
    "# F1 Score\n",
    "def f1_score(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    pre = precision(y_true, y_pred)\n",
    "    rec = true_positive_rate(y_true, y_pred)\n",
    "    res = 2 * ratio(pre * rec, pre + rec)\n",
    "    return check_result(res, \"F1 Score\")\n",
    "\n",
    "#TN/(TN+FN)\n",
    "def negative_predictive_value(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    rprt = binary_prediction_results(y_true, y_pred)\n",
    "    res = ratio(rprt[\"TN\"], rprt[\"TN\"] + rprt[\"FN\"])\n",
    "    return res\n",
    "\n",
    "#Receiver Operating Characteristic Area Under the Curve\n",
    "def roc_auc_score(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    try:\n",
    "        res = sk_metric.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        res = 0\n",
    "    return check_result(res, \"ROC AUC Score\")\n",
    "\n",
    "#Precision-Recall Area Under the Curve\n",
    "def pr_auc_score(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    try:\n",
    "        prc, rec, _ = sk_metric.precision_recall_curve(y_true, y_pred)\n",
    "        res = sk_metric.auc(prc, rec)\n",
    "    except ValueError:\n",
    "        res = np.nan\n",
    "    return check_result(res, \"PR AUC Score\")\n",
    "\n",
    "#PPV=TP/(TP+FP)\n",
    "def precision(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    rprt = binary_prediction_results(y_true, y_pred)\n",
    "    res = ratio(rprt[\"TP\"], rprt[\"TP\"] + rprt[\"FP\"])\n",
    "    return check_result(res, \"Precision\")\n",
    "\n",
    "#TN/(TN+FP)\n",
    "def true_negative_rate(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    rprt = binary_prediction_results(y_true, y_pred)\n",
    "    res = ratio(rprt[\"TN\"], rprt[\"FP\"] + rprt[\"TN\"])\n",
    "    return check_result(res, \"TNR\")\n",
    "\n",
    "#TP/(TP+FN)\n",
    "def true_positive_rate(y_true: ArrayLike, y_pred: ArrayLike):\n",
    "    rprt = binary_prediction_results(y_true, y_pred)\n",
    "    res = ratio(rprt[\"TP\"], rprt[\"FN\"] + rprt[\"TP\"])\n",
    "    return check_result(res, \"TPR\")\n",
    "\n",
    "# Обертывает функции отношения, чтобы возвращать значения NaN вместо 0,0 в случаях где отношение не определено\n",
    "def __manage_undefined_ratios(func: Callable):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        funcname = getattr(func, \"__name__\", \"an unknown function\")\n",
    "        msg = (\n",
    "            \"The ratio is ill-defined and being set to 0.0 because\"\n",
    "            + f\" '{funcname}' for privileged samples is 0.\"\n",
    "        )\n",
    "        with catch_warnings(record=True) as w:\n",
    "            filterwarnings(\"ignore\", message=msg)\n",
    "            res = func(*args, **kwargs)\n",
    "        if len(w) > 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "    #y_true (pd.Series): истинные целевые значения\n",
    "    #y_pred (pd.Series): прогнозируемые целевые значения\n",
    "    #prtc_attr (str): имя защищенного атрибута\n",
    "    #priv_grp (int, optional): привилегированная группа\n",
    "\n",
    "# Возвращает межгрупповое соотношение Postive Predictive Values\n",
    "@__manage_undefined_ratios\n",
    "def ppv_ratio(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return ratio(precision, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает межгрупповое соотношение True Positive Rates\n",
    "@__manage_undefined_ratios\n",
    "def tpr_ratio(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return ratio(true_positive_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает межгрупповое соотношение False Positive Rates\n",
    "@__manage_undefined_ratios\n",
    "def fpr_ratio(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return ratio(false_positive_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает межгрупповое соотношение True Negative Rates\n",
    "@__manage_undefined_ratios\n",
    "def tnr_ratio(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return ratio(true_negative_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает межгрупповое соотношение False Negative Rates\n",
    "@__manage_undefined_ratios\n",
    "def fnr_ratio(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return ratio(false_negative_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает разницу между группами True Positive Rates\n",
    "def tpr_diff(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return difference(true_positive_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает разницу между группами False Positive Rates\n",
    "def fpr_diff(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return difference(false_positive_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает разницу между группами True Negative Rates\n",
    "def tnr_diff(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return difference(true_negative_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает разницу между группами False Negative Rates\n",
    "def fnr_diff(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return difference(false_negative_rate, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "\n",
    "    # Составные метрики (предвзятость) #\n",
    "\n",
    "# Возвращает наибольшее расхождение между разницей FPR между группами и разницей TPR между группами\n",
    "def eq_odds_diff(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    fprD = fpr_diff(y_true, y_pred, pa_name=pa_name, priv_grp=priv_grp)\n",
    "    tprD = tpr_diff(y_true, y_pred, pa_name=pa_name, priv_grp=priv_grp)\n",
    "    if abs(fprD) > abs(tprD):\n",
    "        return fprD\n",
    "    else:\n",
    "        return tprD\n",
    "\n",
    "# Возвращает наибольшее несоответствие между соотношением FPR между группами и соотношением TPR между группами\n",
    "def eq_odds_ratio(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    fprR = fpr_ratio(y_true, y_pred, pa_name=pa_name, priv_grp=priv_grp)\n",
    "    tprR = tpr_ratio(y_true, y_pred, pa_name=pa_name, priv_grp=priv_grp)\n",
    "    if np.isnan(fprR) or np.isnan(tprR):\n",
    "        return np.nan\n",
    "    elif round(abs(fprR - 1), 6) > round(abs(tprR - 1), 6):\n",
    "        return fprR\n",
    "    else:\n",
    "        return tprR\n",
    "\n",
    "# Возвращает разницу PPV значений между группами\n",
    "def ppv_diff(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return difference(precision, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)\n",
    "\n",
    "# Возвращает разницу balanced_accuracy значений между группами\n",
    "def bal_diff(y_true: pd.Series, y_pred: pd.Series, pa_name: str, priv_grp: int = 1):\n",
    "    return difference(balanced_accuracy, y_true, y_pred, prot_attr=pa_name, priv_group=priv_grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db759ef",
   "metadata": {},
   "source": [
    "#### Сводная таблица показателей\n",
    "    Args:\n",
    "        X (pandas DataFrame): Sample features\n",
    "        prtc_attr (named array-like): значения защищенного атрибута (защищенный атрибут может также присутствовать в X)\n",
    "        y_true (pandas DataFrame): действительные\n",
    "        y_pred (pandas DataFrame): предсказанные\n",
    "        y_prob (pandas DataFrame, optional): Выборочные целевые вероятности. По умолчанию None.\n",
    "    Returns:\n",
    "        [type]: [description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cdf9c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_fairness(X, prtc_attr, y_true, y_pred, y_prob=None, priv_grp=1):\n",
    "    #pa_names = prtc_attr.columns.tolist()\n",
    "    pa_names = prtc_attr\n",
    "    gf_vals = {}\n",
    "    gf_key = 'Group Fairness'\n",
    "    \n",
    "    #classified_metric_pred = ClassificationMetric(dataset_true,dataset_pred,unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "    gf_vals['Equal Opportunity Difference'] = equal_opportunity_difference(y_true, y_pred, prot_attr=pa_names)\n",
    "    if not len(pa_names) > 1:\n",
    "        gf_vals['Statictical Parity Difference'] = statistical_parity_difference(y_true, y_pred, sensitive_features=prtc_attr)\n",
    "    gf_vals['Average Odds Difference'] = average_odds_difference(y_true, y_pred, prot_attr=pa_names)\n",
    "    gf_vals['Disparate Impact Ratio'] = disparate_impact_ratio(y_true, y_pred, prot_attr=pa_names)\n",
    "\n",
    "    if not len(pa_names) > 1:\n",
    "        gf_vals['Equal Odds Difference'] = eq_odds_diff(y_true, y_pred, prtc_attr)\n",
    "        gf_vals['Equal Odds Ratio'] = eq_odds_ratio(y_true, y_pred, prtc_attr)\n",
    "\n",
    "    gf_vals['Positive Predictive Parity Difference'] = ppv_diff(y_true, y_pred, pa_names, priv_grp)\n",
    "    gf_vals['Balanced Accuracy Difference'] = bal_diff(y_true, y_pred, pa_names, priv_grp)\n",
    "\n",
    "    return (gf_key, gf_vals)\n",
    "\n",
    "\n",
    "def individual_fairness(X, prtc_attr, y_true, y_pred):\n",
    "    #pa_names = prtc_attr.columns.tolist()\n",
    "    pa_names = prtc_attr\n",
    "    if_vals = {}\n",
    "    if_key = 'Individual Fairness'\n",
    "\n",
    "    if_vals['Consistency Score'] = consistency_score(X, y_pred)\n",
    "    #if_vals['Generalized Entropy'] = generalized_entropy_index()\n",
    "    #if_vals['Theil Index'] = theil_index()\n",
    "    #if_vals['Coefficient of Variation'] = coefficient_of_variation()\n",
    "    #if_vals['Generalized Entropy Error'] = generalized_entropy_error(y_true, y_pred)\n",
    "    #if_vals['Between-Group Generalized Entropy Error'] = between_group_generalized_entropy_error(y_true, y_pred, prot_attr=pa_names)\n",
    "    return (if_key, if_vals)\n",
    "\n",
    "\n",
    "def performance_measures(y_true, y_pred):\n",
    "    #n_class = y_true.append(y_pred).iloc[:, 0].nunique()\n",
    "    #target_labels = [f\"target = {t}\" for t in set(np.unique(y_true))]\n",
    "    #rprt = classification_performance(y_true.iloc[:, 0], y_pred.iloc[:, 0], target_labels)\n",
    "    #avg_lbl = \"weighted avg\" if n_class > 2 else target_labels[-1]\n",
    "    #\n",
    "    mp_vals = {}\n",
    "    mp_key = 'Model Performance'\n",
    "    #for score in ['precision', 'recall', 'f1-score']:\n",
    "        #mp_vals[score.title()] = rprt.loc[avg_lbl, score]\n",
    "    #mp_vals['Accuracy'] = rprt.loc['accuracy', 'accuracy']\n",
    "    mp_vals['Accuracy'] = accuracy(y_true, y_pred)\n",
    "    mp_vals['F1-Score'] = f1_score(y_true, y_pred)\n",
    "    mp_vals['FPR'] = false_positive_rate(y_true, y_pred)\n",
    "    mp_vals['TPR'] = true_positive_rate(y_true, y_pred)\n",
    "    mp_vals['Precision'] = precision(y_true, y_pred)\n",
    "\n",
    "    return (mp_key, mp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e60cc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_fairtest_input(X, prtc_attr, y_true, y_pred, y_prob=None):\n",
    "    valid_data_types = (pd.DataFrame, pd.Series, np.ndarray)\n",
    "    for data in [X, prtc_attr, y_true, y_pred]:\n",
    "        if not isinstance(data, valid_data_types):\n",
    "            raise TypeError(\"input data is invalid type\")\n",
    "        if not data.shape[0] > 1:\n",
    "            raise ValueError(\"input data is too small to measure\")\n",
    "    if y_prob is not None:\n",
    "        if not isinstance(y_prob, valid_data_types):\n",
    "            raise TypeError(\"y_prob is invalid type\")\n",
    "\n",
    "    # Format inputs to required datatypes\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "    if isinstance(prtc_attr, (np.ndarray, pd.Series)):\n",
    "        if isinstance(prtc_attr, pd.Series):\n",
    "            prtc_attr = pd.DataFrame(prtc_attr, columns=[prtc_attr.name])\n",
    "        else:\n",
    "            prtc_attr = pd.DataFrame(prtc_attr)\n",
    "    if isinstance(y_true, (np.ndarray, pd.Series)):\n",
    "        y_true = pd.DataFrame(y_true)\n",
    "    if isinstance(y_pred, np.ndarray):\n",
    "        y_pred = pd.DataFrame(y_pred)\n",
    "    if isinstance(y_prob, np.ndarray):\n",
    "        y_prob = pd.DataFrame(y_prob)\n",
    "    for data in [y_true, y_pred, y_prob]:\n",
    "        if data is not None and data.shape[1] > 1:\n",
    "            raise TypeError(\"targets and predictions must be 1-Dimensional\")\n",
    "\n",
    "    # Format and set sensitive attributes as index for y dataframes\n",
    "    pa_name = prtc_attr.columns.tolist()\n",
    "    prtc_attr.reset_index(inplace=True, drop=True)\n",
    "    y_true = pd.concat([prtc_attr, y_true.reset_index(drop=True)], axis=1).set_index(pa_name)\n",
    "    y_pred = pd.concat([prtc_attr, y_pred.reset_index(drop=True)], axis=1).set_index(pa_name)\n",
    "    y_pred.columns = y_true.columns\n",
    "    if y_prob is not None:\n",
    "        y_prob = pd.concat([prtc_attr, y_prob.reset_index(drop=True)], axis=1).set_index(pa_name)\n",
    "        y_prob.columns = y_true.columns\n",
    "\n",
    "    # Ensure that protected attributes are integer-valued\n",
    "    pa_cols = prtc_attr.columns.tolist()\n",
    "    for c in pa_cols:\n",
    "        binary = (set(prtc_attr[c].astype(int)) == set(prtc_attr[c]))\n",
    "        boolean = (prtc_attr[c].dtype == bool)\n",
    "        two_valued = (set(prtc_attr[c].astype(int)) == {0,1})\n",
    "        if not two_valued and (binary or boolean):\n",
    "            raise ValueError(\"prtc_attr must be binary or boolean and heterogeneous\")\n",
    "        prtc_attr.loc[:, c] = prtc_attr[c].astype(int)\n",
    "        if isinstance(c, int):\n",
    "            prtc_attr.rename(columns={c: f\"prtc_attribute_{c}\"}, inplace=True)\n",
    "\n",
    "    return (X, prtc_attr, y_true, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c1d7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращает dataframe, содержащий меры справедливости для модели.\n",
    "def classification_fairness(X, prtc_attr, y_true, y_pred, y_prob=None,priv_grp=1):\n",
    "    #X, prtc_attr, y_true, y_pred, y_prob = format_fairtest_input(X, prtc_attr, y_true, y_pred, y_prob)\n",
    "\n",
    "    # Generate dict of group fairness measures, if applicable\n",
    "    #n_class = y_true.append(y_pred).iloc[:, 0].nunique()\n",
    "    #if n_class == 2:\n",
    "        #gf_key, gf_vals = group_fairness(X, prtc_attr, y_true, y_pred, y_prob, priv_grp)\n",
    "\n",
    "    gf_key, gf_vals = group_fairness(X, prtc_attr, y_true, y_pred, y_prob, priv_grp)\n",
    "    \n",
    "    #\n",
    "    if_key, if_vals = individual_fairness(X, prtc_attr, y_true, y_pred)\n",
    "\n",
    "    #\n",
    "    mp_key, mp_vals = performance_measures(y_true, y_pred)\n",
    "\n",
    "    # Convert scores to a formatted dataframe and return\n",
    "    measures = {gf_key: gf_vals, if_key: if_vals, mp_key: mp_vals}\n",
    "    df = pd.DataFrame.from_dict(measures, orient=\"index\").stack().to_frame()\n",
    "    df = pd.DataFrame(df[0].values.tolist(), index=df.index)\n",
    "    df.columns = ['Value']\n",
    "    df['Value'] = df.loc[:, 'Value'].round(4)\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95149ae5",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329c194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fairml import audit_model\n",
    "from fairml import plot_dependencies\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tkinter\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f02d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучающие данные\n",
    "df_train = pd.read_csv(\"./input/Webpages_Classification_train_data.csv/Webpages_Classification_train_data.csv\")\n",
    "df_train.drop(columns = \"Unnamed: 0\", inplace = True)\n",
    "\n",
    "# Тренировачные данные\n",
    "df_test = pd.read_csv(\"./input/Webpages_Classification_test_data.csv/Webpages_Classification_test_data.csv\")\n",
    "df_test.drop(columns = \"Unnamed: 0\", inplace = True)\n",
    "\n",
    "# Кодировка стран\n",
    "count = pd.read_csv('./input/tableconvert_csv_pkcsig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7de36e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m df_train\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNetwork\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Признак с количеством специальных знаков\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecial_char\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Длина признака Content\u001b[39;00m\n\u001b[0;32m     39\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent_len\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x))\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     33\u001b[0m df_train\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNetwork\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Признак с количеством специальных знаков\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecial_char\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcount_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Длина признака Content\u001b[39;00m\n\u001b[0;32m     39\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent_len\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x))\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mcount_special\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m     11\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m string:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(\u001b[43mchar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(char\u001b[38;5;241m.\u001b[39misupper()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(char\u001b[38;5;241m.\u001b[39misdigit()):\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     15\u001b[0m             count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "countries = dict(zip(count['Country'], count['Alpha-3 code']))\n",
    "\n",
    "df_train['iso_3'] = df_train['geo_loc']\n",
    "df_train['iso_3'].replace(countries, inplace = True)\n",
    "\n",
    "df_train.https.replace({'yes' : 'HTTPS', 'no' : 'HTTP'}, inplace = True)\n",
    "\n",
    "# Создание новых признаков\n",
    "# Подсчет специальных символов в содержимом\n",
    "def count_special(string):\n",
    "    count = 0\n",
    "    for char in string:\n",
    "        if not(char.islower()) and not(char.isupper()) and not(char.isdigit()):\n",
    "            if char != ' ':\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Определение типа сети [A, B, C]\n",
    "def network_type(ip):\n",
    "    ip_str = ip.split(\".\")\n",
    "    ip = [int(x) for x in ip_str]\n",
    "\n",
    "    if ip[0]>=0 and ip[0]<=127:\n",
    "        return (ip_str[0], \"A\")\n",
    "    elif ip[0]>=128 and ip[0]<=191:\n",
    "        return (\".\".join(ip_str[0:2]), \"B\")\n",
    "    else:\n",
    "        return (\".\".join(ip_str[0:3]), \"C\")\n",
    "    \n",
    "# Добавление признака с типом сети\n",
    "df_train['Network']= df_train['ip_add'].apply(lambda x : network_type(x))\n",
    "df_train['net_part'], df_train['net_type'] = zip(*df_train.Network)\n",
    "df_train.drop(columns = ['Network'], inplace = True)\n",
    "\n",
    "# Признак с количеством специальных знаков\n",
    "df_train['special_char'] = df_train['content'].apply(lambda x: count_special(x))\n",
    "\n",
    "# Длина признака Content\n",
    "df_train['content_len'] = df_train['content'].apply(lambda x: len(x))\n",
    "\n",
    "df_train.label.replace({'bad' : 'Malicious', 'good' : 'Benign'}, inplace = True)\n",
    "\n",
    "df_train.label.replace({'Malicious' : 1, 'Benign' : 0}, inplace = True)\n",
    "\n",
    "ls = ['geo_loc', 'tld', 'who_is', 'https', 'net_type']\n",
    "le_dict = {}\n",
    "\n",
    "for feature in ls:\n",
    "    le = LabelEncoder()\n",
    "    le_dict[feature] = le\n",
    "    df_train[feature] = le.fit_transform(df_train[feature])\n",
    "    \n",
    "# Конечные атрибуты, которые пойду в обучающую выборку\n",
    "df_train = df_train[['url_len', 'geo_loc', 'tld', 'who_is', 'https', 'js_len', 'js_obf_len', 'label', 'net_type', 'special_char', 'content_len']]\n",
    "\n",
    "ss_dict = {}\n",
    "\n",
    "for feature in ['content_len', 'special_char']:\n",
    "    ss = StandardScaler()\n",
    "    ss_fit = ss.fit(df_train[feature].values.reshape(-1, 1))\n",
    "    ss_dict[feature] = ss_fit\n",
    "    d = ss_fit.transform(df_train[feature].values.reshape(-1, 1))\n",
    "    df_train[feature] = pd.DataFrame(d, index = df_train.index, columns = [feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cd73441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.https.replace({'yes' : 'HTTPS', 'no' : 'HTTP'}, inplace = True)\n",
    "df_test.label.replace({'bad' : 'Malicious', 'good' : 'Benign'}, inplace = True)\n",
    "\n",
    "df_test['Network']= df_test['ip_add'].apply(lambda x : network_type(x))\n",
    "df_test['net_part'], df_test['net_type'] = zip(*df_test.Network)\n",
    "df_test.drop(columns = ['Network'], inplace = True)\n",
    "\n",
    "df_test['special_char'] = df_test['content'].apply(lambda x: count_special(x))\n",
    "\n",
    "df_test['content_len'] = df_test['content'].apply(lambda x: len(x))\n",
    "\n",
    "for feature in ls:\n",
    "    le = le_dict[feature]\n",
    "    df_test[feature] = le.fit_transform(df_test[feature])\n",
    "\n",
    "df_test.label.replace({'Malicious' : 1, 'Benign' : 0}, inplace = True)\n",
    "\n",
    "ss_fit = ss_dict['content_len']\n",
    "d = ss_fit.transform(df_test['content_len'].values.reshape(-1, 1))\n",
    "df_test['content_len'] = pd.DataFrame(d, index = df_test.index, columns = ['content_len'])\n",
    "\n",
    "ss_fit = ss_dict['special_char']\n",
    "d = ss_fit.transform(df_test['special_char'].values.reshape(-1, 1))\n",
    "df_test['special_char'] = pd.DataFrame(d, index = df_test.index, columns = ['special_char'])\n",
    "\n",
    "df_test = df_test[['url_len', 'geo_loc', 'tld', 'who_is', 'https', 'js_len', 'js_obf_len', 'label', 'net_type', 'special_char', 'content_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53aa7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8540f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000 train examples\n",
      "361934 test examples\n"
     ]
    }
   ],
   "source": [
    "train= df_train.iloc[:500000,]\n",
    "test= df_test.iloc[:,]\n",
    "\n",
    "print(len(train), 'train examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6888257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label'] \n",
    "X_train = train.drop(columns=['label'])\n",
    "\n",
    "y_test = test['label'] \n",
    "X_test = test.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61a6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "priv_groups = [{'https': 1}]\n",
    "unpriv_groups = [{'https': 0}]\n",
    "#dataset = pd.concat([X_test, y_test], axis=1)\n",
    "#dataset = StandardDataset(dataset, label_name='label', favorable_classes=[0], protected_attribute_names=['https'], privileged_classes=[[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537445bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>net_type</th>\n",
       "      <th>special_char</th>\n",
       "      <th>content_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.281118</td>\n",
       "      <td>-0.303038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>187</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588966</td>\n",
       "      <td>1.828473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.129449</td>\n",
       "      <td>-0.911244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208304</td>\n",
       "      <td>-0.189581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.164800</td>\n",
       "      <td>0.038264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  geo_loc  tld  who_is  https  js_len  js_obf_len  net_type  \\\n",
       "0       36       41  136       0      1    38.5         0.0         1   \n",
       "1       32      187  136       1      1   187.0         0.0         1   \n",
       "2       27       67  136       0      1    31.0         0.0         2   \n",
       "3       56       11  276       0      1   152.0         0.0         0   \n",
       "4       40       41  136       0      1   150.0         0.0         2   \n",
       "\n",
       "   special_char  content_len  \n",
       "0     -0.281118    -0.303038  \n",
       "1      0.588966     1.828473  \n",
       "2     -1.129449    -0.911244  \n",
       "3      0.208304    -0.189581  \n",
       "4      0.164800     0.038264  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ad11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch, DemographicParity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model using GridSearch to optimize for demographic parity\n",
    "fairGridSearch = GridSearch(RandomForestClassifier(),\n",
    "                           constraints=DemographicParity(),\n",
    "                           grid_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bce1bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fairGridSearch\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train, sensitive_features\u001b[38;5;241m=\u001b[39mX_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "fairGridSearch.fit(X_train, y_train, sensitive_features=X_train['https'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c5c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
